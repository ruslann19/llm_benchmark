\newpage

\section{Введение}

Прогресс в области искусственного интеллекта последних лет во многом определяется успехами в разработке больших языковых моделей (Large Language Models, LLM).
Способность этих систем к пониманию, генерации и рассуждению на естественном языке открывает новые перспективы для науки, образования и индустрии.
Однако вместе с ростом возможностей моделей возникает фундаментальный вопрос: как достоверно и объективно измерить их реальную интеллектуальную эффективность.
Традиционные методы оценки, основанные на фиксированных наборах данных, сталкиваются с непреодолимым противоречием: модели развиваются быстрее, чем успевают создаваться адекватные инструменты для их тестирования.

Основная проблема современных подходов к оценке заключается в трёх ключевых ограничениях.
\begin{itemize}
    \item Первое ограничение -- это статичность и насыщаемость большинства существующих наборов данных для тестирования.
    \item Второе -- отсутствие механизмов для проверки работы модели со свежей, актуальной информацией.
    \item Третье -- сложность масштабирования и адаптации методов извлечения структурированных данных из неоднородных и меняющихся источников.
\end{itemize}
Эти вызовы делают необходимым создание не просто нового набора вопросов, а целой методологии и инфраструктуры для их автоматизированного, гибкого и масштабируемого пополнения.

Целью данной научно-исследовательской работы является разработка и апробация прототипа обновляемого бенчмарка для оценки общих знаний LLM.
Предметом исследования выступают методы построения динамических оценочных систем с использованием самих языковых моделей для автоматизации ключевых процессов.
Ключевой задачей является создание конвейера, способного извлекать вопросы и ответы из сложноструктурированных, но регулярно обновляемых источников.

В качестве основного источника данных для бенчмарка была выбрана популярная российская телевикторина ``Своя игра''.
Её текстовые расшифровки, публикуемые на специализированном форуме, представляют собой качественный, верифицированный и постоянно пополняемый массив вопросов.
Данный источник позволяет проверять широкий спектр общих знаний и эрудицию на русском языке.
Для решения задачи извлечения структурированных данных из вариативных текстовых описаний был применён инновационный подход -- использование LLM в качестве универсального парсера.
В работе использовалось API модели DeepSeek для преобразования неструктурированного текста в формализованные пары ``вопрос--ответ''.
Этот подход преодолевает хрупкость регулярных выражений и вычислительную затратность обучения специализированных моделей.
Он обеспечивает устойчивость к изменениям формата исходных данных и высокую степень масштабируемости для подключения новых источников в будущем.

Таким образом, разрабатываемый бенчмарк представляет собой саморазвивающуюся оценочную систему.
Его архитектура основана на автоматизированном конвейере, который обеспечивает постоянное пополнение базы новыми, актуальными вопросами.
Это позволяет проводить оценку LLM на данных, которые гарантированно не входили в их предобучение, и проверять способность работать со знаниями о постоянно меняющемся мире.
