\newpage

\section{Введение}

Большие языковые модели (Large Language Models, LLM) за последние годы продемонстрировали стремительный прогресс как в качестве генерации текста, так и в способности решать широкий спектр задач — от ответов на вопросы и написания кода до логических рассуждений и творческого письма.
Вместе с этим ростом возникает острая необходимость в объективной, надёжной и актуальной оценке их возможностей.
Стандартные подходы к бенчмаркингу, основанные на фиксированных наборах данных, быстро устаревают: знания в мире постоянно обновляются, а модели всё чаще обучаются на данных, включающих информацию, появившуюся после публикации классических датасетов.
Это приводит к завышенным оценкам производительности и снижает прогностическую ценность таких тестов.

В рамках данной научно-исследовательской работы разработан новый бенчмарк, ориентированный на оценку \textbf{общих знаний} больших языковых моделей \textbf{на русском языке}.
Ключевой особенностью предложенного подхода является его \textbf{обновляемость}: в отличие от статичных бенчмарков, он позволяет регулярно пополнять и актуализировать набор вопросов, отражая текущее состояние знаний и событий.
Такой подход обеспечивает более реалистичную и долгосрочную оценку способности моделей адаптироваться к новой информации и демонстрировать актуальные знания, что особенно важно в условиях динамично меняющегося информационного ландшафта.
