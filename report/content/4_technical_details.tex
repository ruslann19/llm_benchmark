\newpage

\section{Техническая реализация}

\subsection*{Выбор и обоснование технологий}

\subsubsection*{LLM как универсальный парсер}

Извлечение структурированных вопросно-ответных пар из неоднородных текстовых отчётов представляет собой нетривиальную задачу.

\begin{itemize}
    \item \textbf{Проблематика традиционных подходов:}
          \begin{itemize}
              \item \textbf{Регулярные выражения (RegEx):} Из-за постоянных вариаций в формате текстовых отчётов (разметка, порядок блоков, оформление) создание и поддержка набора правил является \emph{хрупким и трудномасштабируемым} решением. Любое изменение в источнике требует модификации кода.
              \item \textbf{Специализированные ML-модели (NER, Information Extraction):} Обучение собственной модели для распознавания сущностей и отношений требует размеченного датасета, значительных вычислительных ресурсов для обучения и не гарантирует обобщения на новые форматы данных без дообучения.
          \end{itemize}

    \item \textbf{Предлагаемое решение:} Использование API большой языковой модели (в данном прототипе -- \textbf{DeepSeek}) в качестве ядра парсинга. LLM получает на вход необработанный текст и текстовую инструкцию (prompt), детально описывающую ожидаемый выход -- структурированный JSON-объект.

    \item \textbf{Преимущества подхода:}
          \begin{itemize}
              \item \textbf{Устойчивость к изменениям:} При изменении формата исходных данных корректируется лишь текстовая инструкция для LLM, а не логика парсера.
              \item \textbf{Контекстное понимание:} Модель способна корректно интерпретировать сокращения, косвенные формулировки, извлекать ответы из повествовательных предложений.
              \item \textbf{Нулевое обучение (Zero-shot/Few-shot):} Для работы не требуется предварительное обучение на размеченных данных конкретного источника.
              \item \textbf{Лёгкость масштабирования:} Для подключения нового источника (новостная лента, другая викторина) достаточно создать для него новый промпт.
          \end{itemize}
\end{itemize}
Пример промпта, используемого для парсинга ``Своей игры'':
\begin{verbatim}
Извлеки все пары вопрос-ответ из текста ниже. Верни ТОЛЬКО валидный JSON-массив.
Не добавляй пояснений, комментариев, маркеров кода (типа ```json).
Каждый элемент массива — объект с двумя полями: "question" (строка) и "answer" (строка).
Выведи пары в формате JSONL: один JSON-объект на строку.

Пример:
{"question": "Какая столица в России?", "answer": "Москва"}
{"question": "Сколько будет 2 + 2?", "answer": "4"}
{"question": "Сколько округов в Париже?", "answer": "20"}

Текст: {text}
\end{verbatim}

\subsubsection*{Хранение данных}

Для хранения данных была выбрана иерархическая схема, начиная с простого решения для прототипа с перспективой роста.

\begin{itemize}
    \item \textbf{Текущая СУБД: SQLite}
          \begin{itemize}
              \item \textbf{Причина выбора:} Простота развёртывания (один файл), отсутствие необходимости в отдельном сервере и управлении пользователями. Идеально подходит для этапа прототипирования и локальной разработки.
              \item \textbf{Недостатки:} Ограниченная производительность при высокой конкурентной нагрузке, отсутствие продвинутых механизмов параллелизма, что делает её неподходящей для production-среды с множеством одновременных запросов.
          \end{itemize}

    \item \textbf{Планируемая СУБД: PostgreSQL}
          \begin{itemize}
              \item \textbf{Причина миграции:} Потребность в надёжной системе управления данными для будущего публичного API и веб-интерфейса. PostgreSQL обеспечит стабильность, производительность, поддержку сложных запросов, полнотекстового поиска и удобное масштабирование.
          \end{itemize}
\end{itemize}

\subsection*{Архитектура базы данных}

Ниже представлена упрощённая схема основных таблиц базы данных и их взаимосвязей.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.4\textwidth]{img/db_relations.png}
    \caption{Схема взаимосвязей таблиц в базе данных бенчмарка}
\end{figure}

\newpage

\textbf{Описание таблиц:}
\begin{itemize}
    \item \texttt{tasks} -- Верифицированные задачи, готовые к использованию. Статус каждой задачи меняется в процессе эксплуатации бенчмарка: \texttt{'queue'} \(\rightarrow\) \texttt{'benchmark'} \(\rightarrow\) \texttt{'archive'}. На каждой итерации обновления бенчмарака используется поле \\ \texttt{benchmark\_version} - для версионирования бенчмарка и отслежавания истории измерений.
    \item \texttt{llm\_infos} -- Каталог тестируемых языковых моделей (GPT, Claude, Llama и др.).
    \item \texttt{llm\_responses} -- Ответы моделей на вопросы. Каждая запись связана с задачей и с моделью. Также в таблице хранится вердикт LLM-as-a-Judge - верен ли ответ модели.
\end{itemize}

\subsection*{Управление через командную строку (CLI)}

На текущем этапе управление бенчмарком осуществляется через консольное приложение. Это позволяет гибко управлять процессом и интегрировать его в скрипты.

\subsubsection*{Команда \texttt{collect\_tasks [url]}}

Выполняет сбор и первоначальную обработку данных с указанного URL.

\textbf{Алгоритм работы:}
\begin{enumerate}
    \item Загрузка HTML-страницы по указанному URL.
    \item Извлечение основного текстового контента (игнорирование шапки, навигации, рекламы).
    \item Отправка очищенного текста в LLM (DeepSeek API) с промптом для парсинга.
    \item Получение и валидация JSON-ответа от LLM.
    \item Сохранение извлечённых задач в таблицу \texttt{tasks} со статусом \texttt{'queue'}.
\end{enumerate}

Получение структурированных данных от LLM выполняется в формате \\ JSONL.
Этот формат представляет из себя последовательность JSON-обектов, каждый на новой строке, без каких-либо лишних разделителей.
Это позволяет считывать задачи в реальном времени и отслеживать прогресс.
Также этот формат более устойчив к ошибкам форматирования.
Объекты парсятся и сохраняются независимо друг от друга.
Поэтому, если в одном из объектов возникнет синтаксическая ошибка, программа сможет безошибочно обработать остальные объекты - они будут добавлены в базу данных.
В классическом же формате список объектов воспринимался бы как неделимый элемент.
И ошибка в одном из элементов приводила бы к ошибке парсинга всего текста.

\subsubsection*{Команда \texttt{update\_benchmark}}

Ключевая команда, выполняющая ротацию задач в активном бенчмарке и запускающая тестирование.

\textbf{Алгоритм работы:}
\begin{enumerate}
    \item \textbf{Проверка очереди:} Определяется количество задач со статусом \texttt{'queue'} в \texttt{tasks}. Если их меньше порогового значения (например, \(N = 100\)), процесс прерывается с соответствующим сообщением.
    \item \textbf{Архивация текущей версии:} Задачи, входящие в текущую активную версию бенчмарка, помечаются как архивные.
    \item \textbf{Создание новой версии:} В \texttt{benchmark\_versions} создаётся новая запись с увеличенным номером версии и текущей датой. Она становится активной.
    \item \textbf{Наполнение новой версии:} Первые \(N\) задач из очереди (\texttt{'queue'}) переносятся в бенчмарк (\texttt{'benchmark'}).
    \item \textbf{Автоматический запуск тестирования:}
          \begin{enumerate}
              \item Для каждой модели из \texttt{llm\_models} (помеченной для автотестирования) и для каждой новой задачи в созданной версии:
                    \begin{itemize}
                        \item Вопрос отправляется в соответствующее API модели.
                        \item Ответ сохраняется в \texttt{model\_responses}.
                        \item \textbf{Оценка ответов (LLM-as-a-Judge):} Для каждой тройки \texttt{(вопрос, эталонный\_ответ, ответ\_модели)} запускается процесс судейства. Отдельная LLM (на данный момент - DeepSeek) выступает в роли судьи. Она получает инструкцию сравнить два ответа на предмет семантической эквивалентности и вынести вердикт (\texttt{'OK'}, \texttt{'FAIL'}). Вердикт сохраняется в \texttt{llm\_responses.is\_valid}.
                    \end{itemize}
                    %   \item Рассчитываются и выводятся в консоль агрегированные метрики (accuracy) для каждой модели по новой версии бенчмарка.
          \end{enumerate}
\end{enumerate}

\subsection*{Планы по развитию}

\begin{itemize}
    \item \textbf{Автоматизация сбора:} Реализация фонового демона (daemon), который будет по расписанию (например, раз в сутки) проверять источники на наличие новых данных и запускать \texttt{collect\_tasks} автоматически. Требует переноса системы на хостинг с постоянно работающим сервером.
    \item \textbf{Веб-интерфейс:} Разработка графического интерфейса пользователя (GUI) для:
          \begin{itemize}
              \item Удобного просмотра лидербордов и истории версий.
              \item Визуализации результатов (графики, сравнение моделей).
              \item Управления источниками и моделями.
              \item Ручной верификации спарсенных задач.
          \end{itemize}
          % \item \textbf{REST API:} Создание публичного API для программного доступа к бенчмарку, что позволит интегрировать его в сторонние системы и инструменты исследователей.
    \item \textbf{Расширение источников:} Интеграция парсеров для дополнительных викторин и новостных агрегаторов.
\end{itemize}
